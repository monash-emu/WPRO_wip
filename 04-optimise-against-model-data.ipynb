{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d316eb3c-d354-439c-ad0b-e896bb350ce8",
   "metadata": {},
   "source": [
    "## Test optimisation algorithms against results produced by model with known parameters\n",
    "Using a similar approach to the preceding notebooks ($i_t = R_t\\sum_{\\tau<t} i_\\tau g_{t-\\tau}$),\n",
    "test various optimisation algorithms using model-created outputs\n",
    "(so that we know the ideal parameters that the algorithm should be approaching).\n",
    "So that we can start using these various model components in more sophisticated ways,\n",
    "I'll begin writing the code as properly encapsulated functions\n",
    "and tracking a few key model quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49b5a0-50c7-468d-acfa-0a9a5ea6e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "from scipy.optimize import minimize, shgo\n",
    "import nevergrad as ng\n",
    "\n",
    "from emu_renewal.renew import RenewalModel\n",
    "from emu_renewal.outputs import plot_output_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fafa18-a445-4df5-a223-ed02eb23f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_process = [1.8, 2.5, 1.6, 0.7]\n",
    "n_times = 40\n",
    "model = RenewalModel(100.0, n_times, 10, 5)\n",
    "gen_mean = 5.5\n",
    "gen_sd = 1.8\n",
    "seed = 1.0\n",
    "test_results = model.func(gen_mean, gen_sd, np.log(test_process), seed).incidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d42533-c135-4c09-a22f-12b64c101fe1",
   "metadata": {},
   "source": [
    "### Local optimisation algorithm\n",
    "#### Process values optimised only\n",
    "Local optimisation algorithm.\n",
    "It works for this simple case, but quickly breaks down in many other use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84825c-4a0f-43c2-9772-2ca5664abf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calib_func(parameters: List[float], targets: dict) -> float:\n",
    "    incidence = model.func(gen_mean, gen_sd, parameters, seed).incidence\n",
    "    return sum([(incidence[t] - d) ** 2 for t, d in enumerate(targets)])\n",
    "\n",
    "param_bounds = [[-1000.0, np.log(10.0)]] * 4\n",
    "result = minimize(calib_func, [np.log(2.0)] * 4, method='Nelder-Mead', args=(test_results), bounds=param_bounds)\n",
    "\n",
    "print(f'target: {test_process}')\n",
    "print(f'result: {np.exp(result.x)}')\n",
    "inc = model.func(gen_mean, gen_sd, result.x, seed).incidence\n",
    "pd.DataFrame({'opt': inc, 'target': test_results}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca7386-b374-4be0-8913-bb07b43564da",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generation time parameters included\n",
    "The same local optimisation algorithm, \n",
    "but now additionally including generation time parameters in local optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdb4d0-eba8-49da-b645-b2e85f7176ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calib_func(parameters: List[float], targets: dict) -> float:\n",
    "    gen_mean, gen_sd, *parameters = parameters\n",
    "    incidence = model.func(gen_mean, gen_sd, parameters, seed).incidence\n",
    "    return sum([(incidence[t] - d) ** 2 for t, d in enumerate(targets)])\n",
    "\n",
    "param_bounds = [[1.0, 10.0]] + [[1.0, 5.0]] + [[-10000.0, np.log(10.0)]] * 4\n",
    "result = minimize(calib_func, [5.0, 1.5] + [np.log(2.0)] * 4, method='Nelder-Mead', args=(test_results), bounds=param_bounds)\n",
    "\n",
    "print(f'target: {gen_mean}, {gen_sd}, {test_process}')\n",
    "print(f'result: {result.x[0]}, {result.x[1]}, {np.exp(result.x[2:])}')\n",
    "inc = model.func(result.x[0], result.x[1], result.x[2:], seed).incidence\n",
    "pd.DataFrame({'opt': inc, 'target': test_results}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d954d5-2437-477e-bd67-35c64981f092",
   "metadata": {},
   "source": [
    "### Global algorithm\n",
    "Global optimisation with `scipy`'s `shgo` - need to capture arguments through closure due to bug in optimisation function\n",
    "as per [comment found online](https://stackoverflow.com/questions/72794609/scipy-issue-passing-arguments-to-optimize-shgo-function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe849e-392b-4d2c-8722-8c41c0d108ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_result = shgo(lambda x, d=test_results: calib_func(x, d), param_bounds)\n",
    "\n",
    "print(f'target: {gen_mean}, {gen_sd}, {test_process}')\n",
    "print(f'result: {global_result.x[0]}, {global_result.x[1]}, {np.exp(global_result.x[2:])}')\n",
    "inc = model.func(global_result.x[0], global_result.x[1], global_result.x[2:], seed).incidence\n",
    "pd.DataFrame({'opt': inc, 'target': test_results}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d2941-b31f-4b2f-a463-72db3a705323",
   "metadata": {},
   "source": [
    "### `nevergrad` algorithms\n",
    "#### `NGOpt` with default settings\n",
    "`NGOpt` applied without additional user requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd0cc9-6a4b-4b1a-a51a-1a996765ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_func(parameters):\n",
    "    return calib_func(parameters, targets=test_results)\n",
    "\n",
    "optimizer = ng.optimizers.NGOpt(parametrization=6, budget=2000)\n",
    "ngopt_result = optimizer.minimize(obj_func)\n",
    "\n",
    "print(f'target: {gen_mean}, {gen_sd}, {test_process}')\n",
    "print(f'result: {ngopt_result.value[0]}, {ngopt_result.value[1]}, {np.exp(ngopt_result.value[2:])}')\n",
    "inc = model.func(ngopt_result.value[0], ngopt_result.value[1], ngopt_result.value[2:], seed).incidence\n",
    "pd.DataFrame({'opt': inc, 'target': test_results}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77311aa9-f00d-4bd0-ad08-50c801579227",
   "metadata": {},
   "source": [
    "#### `NGOpt` with parameterisation\n",
    "Specify starting points and bounds for algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57a58a-c84f-4ccf-8baf-b79c4304176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_time_mean_param = ng.p.Scalar(init=5.0, lower=0.1, upper=10.0)\n",
    "gen_time_sd_param = ng.p.Scalar(init=1.0, lower=0.1, upper=4.0)\n",
    "process_param = ng.p.Array(init=[0.0] * 4, lower=-10.0, upper=10.0)\n",
    "instrum = ng.p.Instrumentation(gen_time_mean_param, gen_time_sd_param, process_param)\n",
    "\n",
    "def obj_func(gen_time_mean, gen_time_sd, parameters):\n",
    "    return calib_func([gen_time_mean, gen_time_sd] + list(parameters), targets=test_results)\n",
    "\n",
    "optimizer = ng.optimizers.NGOpt(parametrization=instrum, budget=2000)\n",
    "ngopt_result = optimizer.minimize(obj_func).value[0]  # Zero index gets us the args (not kwargs)\n",
    "print(f'target: {gen_mean}, {gen_sd}, {test_process}')\n",
    "print(f'result: {ngopt_result[0]}, {ngopt_result[1]}, {np.exp(ngopt_result[2:])}')\n",
    "inc = model.func(ngopt_result[0], ngopt_result[1], ngopt_result[2:][0], seed).incidence\n",
    "pd.DataFrame({'opt': inc, 'target': test_results}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d4de3b-495c-4d15-99df-c22f9ad70beb",
   "metadata": {},
   "source": [
    "#### `TwoPointsDE`\n",
    "An alternative `nevergrad` optimiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9668ec7-615b-42b2-9242-b02668ce560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ng.optimizers.TwoPointsDE(parametrization=instrum, budget=2000)\n",
    "ngopt_result = optimizer.minimize(obj_func).value[0]\n",
    "\n",
    "print(f'target: {gen_mean}, {gen_sd}, {test_process}')\n",
    "print(f'result: {ngopt_result[0]}, {ngopt_result[1]}, {np.exp(ngopt_result[2:])}')\n",
    "inc = model.func(ngopt_result[0], ngopt_result[1], ngopt_result[2:][0], seed).incidence\n",
    "pd.DataFrame({'opt': inc, 'target': test_results}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2d766-f91b-4878-80ad-6d4ccb0f248c",
   "metadata": {},
   "source": [
    "#### `NGOpt` optimisation with jittered synthetic data\n",
    "Same as previous best algorithm, but with jitter applied to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da5ad0-cea0-4cfe-8910-2bce6105b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = 0.2\n",
    "jitter = pd.Series(np.random.normal(scale=spread, size=n_times) + 1.0)\n",
    "jittered_vals = test_results * jitter\n",
    "\n",
    "optimizer = ng.optimizers.NGOpt(parametrization=instrum, budget=2000)\n",
    "jitter_result = optimizer.minimize(obj_func).value[0]\n",
    "\n",
    "print(f'target: {gen_mean}, {gen_sd}, {test_process}')\n",
    "print(f'result: {ngopt_result[0]}, {ngopt_result[1]}, {np.exp(ngopt_result[2:])}')\n",
    "inc = model.func(ngopt_result[0], ngopt_result[1], ngopt_result[2:][0], seed).incidence\n",
    "pd.DataFrame({'opt': inc, 'target': jittered_vals}).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
