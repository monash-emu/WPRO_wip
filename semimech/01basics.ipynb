{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d316eb3c-d354-439c-ad0b-e896bb350ce8",
   "metadata": {},
   "source": [
    "## Semi-mechanistic modelling exploration\n",
    "\n",
    "### Rationale\n",
    "Thinking about this equation in Faria, et al:\n",
    "$\\\\i_{s,t} = (1-\\frac{n_{s,t}}{N})R_{s,t}\\sum_{\\tau<t} i_{s,\\tau}g_{t-\\tau}$\n",
    "\n",
    "For me, this is a more standard \"semi-mechanistic\" modelling approach,\n",
    "in that the population is not explicitly partitioned into categories or compartments.\n",
    "It is partitioned in this way for our standard compartmental models,\n",
    "including both standard SEIR `summer` models, \n",
    "as well as Romain's semi-mechanistic models,\n",
    "which are compartmental with an additional non-mechanistic random walk \n",
    "flow adjustment.\n",
    "\n",
    "First, ignoring strains, I'll consider:\n",
    "$\\\\i_t = (1-\\frac{n_t}{N})R_t\\sum_{\\tau<t} i_{\\tau}g_{t-\\tau}$\n",
    "\n",
    "For now, I'll also ignore susceptible depletion and a varying reproduction number, and so consider:\n",
    "$\\\\i_t = R_0\\sum_{\\tau<t} i_\\tau g_{t-\\tau}$\n",
    "\n",
    "This notebook builds up the basic code from the first principles,\n",
    "checking with each extension that the results we are getting back are the same\n",
    "as in the previous, more explicit version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49b5a0-50c7-468d-acfa-0a9a5ea6e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from scipy.stats import gamma\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a8d10-fc2f-4851-855d-19a0f72c8013",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parameters\n",
    "Choose some arbitrary model parameters to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37777223-4e4b-4b55-b6a0-122cf31a2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_times = 20\n",
    "seed = 1.0\n",
    "r0 = 2.0\n",
    "incidence = np.zeros(n_times)\n",
    "incidence[0] = seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3136042-a7b8-4887-9a3e-9f87525f4e22",
   "metadata": {},
   "source": [
    "### Generation time\n",
    "Get a distribution we can sensibly use for the generation time,\n",
    "which could represent an acute immunising respiratory infection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a343bc7-c944-45a2-a089-839a5699ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gamma_params_from_mean_sd(req_mean: float, req_sd: float) -> Dict[str, float]:\n",
    "    var = req_sd ** 2.0\n",
    "    scale = var / req_mean\n",
    "    a = req_mean / scale\n",
    "    return {'a': a, 'scale': scale}\n",
    "\n",
    "# Generation time parameters\n",
    "req_sd = 1.5\n",
    "req_mean = 5.0\n",
    "gamma_params = get_gamma_params_from_mean_sd(req_mean, req_sd)\n",
    "\n",
    "# Get the increment in the CDF\n",
    "# (i.e. the integral over the increment by one in the distribution)\n",
    "gen_time_densities = np.diff(gamma.cdf(range(n_times + 1), **gamma_params))\n",
    "\n",
    "pd.Series(gen_time_densities, index=range(n_times)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf8f7a5-d9a4-4724-9d67-bcc079f9a7c3",
   "metadata": {},
   "source": [
    "### Check calculations make sense from first principles\n",
    "Looping in Python to be completely explicit (with pre-calculated generation times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953951d-c3e6-4b7e-a34c-0ba04c5878b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1, n_times):\n",
    "    val = 0\n",
    "    for tau in range(t):  # For each day preceding the day of interest\n",
    "        delay = t - tau - 1  # The generation time index for each preceding day to the day of interest\n",
    "        val += incidence[tau] * gen_time_densities[delay] * r0  # Calculate the incidence value\n",
    "    incidence[t] = val\n",
    "incidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79049f42-ea25-4774-b241-c50b36606aa7",
   "metadata": {},
   "source": [
    "Get rid of one loop to get lists/arrays for the incidence and generation time distribution \n",
    "(and check that calculations are the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d2fe8-96fb-4534-b185-7c02bbdb7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1, n_times):\n",
    "    delays = [t - tau - 1 for tau in range(t)]\n",
    "    gammas = gen_time_densities[delays]\n",
    "    incidence[t] = (incidence[:t] * gammas).sum() * r0\n",
    "incidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d417c5c5-b6c5-4e68-9552-87a76fe24af7",
   "metadata": {},
   "source": [
    "We can get this down to a one-liner if preferred. This is going to just keep going up exponentially, of course, because $R_{0} > 1$ and there is no susceptible depletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5bc8b-65f9-4375-ac92-f639be572dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1, n_times):\n",
    "    incidence[t] = (incidence[:t] * gen_time_densities[:t][::-1]).sum() * r0\n",
    "incidence\n",
    "pd.Series(incidence).plot(labels={'index': 'day', 'value': 'incidence'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e9349-423b-4b43-9fc0-b4d2ab5c17ad",
   "metadata": {},
   "source": [
    "Already some interesting phenomena there, \n",
    "in that the humps are the generations of cases from the first seeding infection,\n",
    "which progressively smooth into one-another with generations of cases.\n",
    "\n",
    "### Threshold behaviour\n",
    "Next let's check that the threshold behaviour is approximately correct.\n",
    "We would expect a declining epidemic with $R_{0} < 1$ even without\n",
    "susceptible depletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b94e876-43cf-4b03-9ce3-9be6ee78e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = 0.8\n",
    "for t in range(1, n_times):\n",
    "    incidence[t] = (incidence[:t] * gen_time_densities[:t][::-1]).sum() * r0\n",
    "incidence\n",
    "pd.Series(incidence).plot(labels={'index': 'day', 'value': 'incidence'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
